{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secion3 実装演習コード\n",
    "\n",
    "TensorFlowチュートリアル掲載コードを参考に、float16量子化モデルを作成する。量子化なしモデルとの精度、処理速度、サイズ比較を行い、量子化効果を確認する。\n",
    "\n",
    "参考URL\n",
    "https://www.tensorflow.org/lite/performance/post_training_float16_quant?hl=ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2885 - accuracy: 0.9191 - val_loss: 0.1407 - val_accuracy: 0.9601\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\shima\\AppData\\Local\\Temp\\tmpg713m5jp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shima\\AppData\\Local\\Temp\\tmpg713m5jp\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shima\\AppData\\Local\\Temp\\tmpmciabwus\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shima\\AppData\\Local\\Temp\\tmpmciabwus\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model : accuracy= 0.9601 , time[ms]= 1941.8909549713135\n",
      "Quantization Model(fp16) : accuracy= 0.9601 , time[ms]= 1938.124179840088\n"
     ]
    }
   ],
   "source": [
    "# 参考: TensorFlowチュートリアル\n",
    "#  https://www.tensorflow.org/lite/performance/post_training_float16_quant?hl=ja\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_imgs, test_lbls) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "\n",
    "# ----------------\n",
    "#  通常モデル作成\n",
    "# ----------------\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=1,\n",
    "  validation_data=(test_imgs, test_lbls)\n",
    ")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# ファイルダンプ\n",
    "tflite_models_dir = pathlib.Path(\"./fig_section3/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "# モデルをインタープリタに読み込む\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# -------------------\n",
    "#  量子化モデルに変換\n",
    "# -------------------\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "# ファイルダンプ\n",
    "tflite_model_fp16_file = tflite_models_dir/\"mnist_model_quant_f16.tflite\"\n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n",
    "\n",
    "# モデルをインタープリタに読み込む\n",
    "interpreter_fp16 = tf.lite.Interpreter(model_path=str(tflite_model_fp16_file))\n",
    "interpreter_fp16.allocate_tensors()\n",
    "\n",
    "# ----------------\n",
    "#  モデル比較\n",
    "# ----------------\n",
    "\n",
    "import time\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(model_interp, test_images, test_labels):\n",
    "    input_index = model_interp.get_input_details()[0][\"index\"]\n",
    "    output_index = model_interp.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    start = time.time()\n",
    "\n",
    "    prediction_digits = []\n",
    "    for test_image in test_images:\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        model_interp.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        model_interp.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = model_interp.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    elapsed_time = (time.time() - start) * 1000\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_digits)):\n",
    "        if prediction_digits[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "    return accuracy, elapsed_time\n",
    "\n",
    "# 通常モデルの評価\n",
    "acc_normal, time_normal = evaluate_model(interpreter, test_imgs, test_lbls)\n",
    "\n",
    "# 量子化モデルの評価\n",
    "acc_quant, time_quant = evaluate_model(interpreter_fp16, test_imgs, test_lbls)\n",
    "\n",
    "print(\"Normal Model : accuracy=\", acc_normal, \n",
    "        \", time[ms]=\", time_normal)\n",
    "\n",
    "print(\"Quantization Model(fp16) : accuracy=\", acc_quant, \n",
    "        \", time[ms]=\", time_quant)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "734fcb2955e61c95bc52e7ba333639f24418f21fd62fa5806387fd056a54dca5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('studyai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
